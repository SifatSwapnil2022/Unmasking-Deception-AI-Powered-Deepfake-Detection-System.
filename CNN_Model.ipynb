{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvHiYyX3k1WZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import Sequence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AIycLO6pmBQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up paths\n",
        "train_dir = '/content/drive/MyDrive/Artificial Intelligence part_1/Test'\n",
        "test_dir = '/content/drive/MyDrive/Artificial Intelligence part_1/Train'\n",
        "val_dir = '/content/drive/MyDrive/Artificial Intelligence part_1/Validation'"
      ],
      "metadata": {
        "id": "7apyevHSlGQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to add Gaussian noise\n",
        "def add_noise(img):\n",
        "    noise_factor = 0.1  # Adjust for noise level\n",
        "    noisy_img = img + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=img.shape)\n",
        "    noisy_img = np.clip(noisy_img, 0.0, 1.0)  # Ensure values are between 0 and 1\n",
        "    return noisy_img"
      ],
      "metadata": {
        "id": "1H-3i9LvlJNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Data Generator with noise addition\n",
        "class NoisyImageDataGenerator(Sequence):\n",
        "    def __init__(self, generator):\n",
        "        self.generator = generator\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.generator)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        images, labels = self.generator[index]\n",
        "        noisy_images = np.array([add_noise(img) for img in images])  # Apply noise\n",
        "        return noisy_images, labels"
      ],
      "metadata": {
        "id": "5PM1yJc6lMOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data generators\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "train_generator = NoisyImageDataGenerator(train_generator)  # Add noise\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "QpuvFpf9lQOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ],
      "metadata": {
        "id": "FUllwr11lZ5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=val_generator\n",
        ")\n"
      ],
      "metadata": {
        "id": "DAEhM8inlgDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "id": "IIp1l90hlioZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = (predictions > 0.5).astype(int)\n",
        "true_classes = test_generator.classes\n",
        "class_labels = list(test_generator.class_indices.keys())"
      ],
      "metadata": {
        "id": "tZz3g_53ltPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Example Confusion Matrix Data\n",
        "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Create a custom color map for each cell\n",
        "cell_colors = np.array([\n",
        "    ['#FFCCCC', '#FF6666'],  # Light and dark red for row 1\n",
        "    ['#66B2FF', '#0033CC']   # Light and dark blue for row 2\n",
        "])\n",
        "\n",
        "# Plot the confusion matrix with custom cell colors\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cbar=False, linewidths=1,\n",
        "            linecolor='black', xticklabels=class_labels, yticklabels=class_labels,\n",
        "            square=True, cmap=None, annot_kws={\"size\": 15}, mask=None)\n",
        "\n",
        "# Loop through each cell to manually set the background color\n",
        "ax = plt.gca()\n",
        "for i in range(conf_matrix.shape[0]):  # Rows\n",
        "    for j in range(conf_matrix.shape[1]):  # Columns\n",
        "        ax.add_patch(plt.Rectangle((j, i), 1, 1, color=cell_colors[i][j], alpha=0.5))\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Confusion Matrix ')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.xticks(ticks=np.arange(len(class_labels)) + 0.5, labels=class_labels, rotation=45)\n",
        "plt.yticks(ticks=np.arange(len(class_labels)) + 0.5, labels=class_labels, rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6tcvVK7_lt41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "id": "ndA3lzwxly1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Performance\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fzNva1Ysl08S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Check Test Data Predictions (Real or Fake)\n",
        "test_filenames = test_generator.filenames\n",
        "\n",
        "# Define the number of images to display\n",
        "num_images_to_display = 20\n",
        "\n",
        "# Create a grid layout for better visualization\n",
        "rows, cols = 4, 5  # Adjust based on the number of images\n",
        "plt.figure(figsize=(15, 12))\n",
        "\n",
        "for i in range(num_images_to_display):\n",
        "    img_path = test_dir + '/' + test_filenames[i]\n",
        "    img = plt.imread(img_path)\n",
        "\n",
        "    # Get the prediction\n",
        "    prediction = 'Real' if predicted_classes[i][0] == 0 else 'Fake'\n",
        "\n",
        "    # Plot the image\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicted: {prediction}\", fontsize=10)\n",
        "    plt.axis('off')\n",
        "\n",
        "# Add a title to the overall grid\n",
        "plt.suptitle(\"Test Data Predictions (Real or Fake)\", fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to fit title\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LRHJxz4Ul1k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############# fake ELA\n",
        "\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def perform_ela(image_path, quality=95):\n",
        "\n",
        "\n",
        "\n",
        "    original = Image.open(image_path).convert('RGB')\n",
        "\n",
        "\n",
        "    temp_path = 'temp_compressed.jpg'\n",
        "    original.save(temp_path, 'JPEG', quality=quality)\n",
        "\n",
        "\n",
        "    compressed = Image.open(temp_path)\n",
        "\n",
        "    ela_image = ImageChops.difference(original, compressed)\n",
        "\n",
        "\n",
        "    extrema = ela_image.getextrema()\n",
        "    max_diff = max([ex[1] for ex in extrema])\n",
        "    scale = 255.0 / max_diff if max_diff != 0 else 1\n",
        "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
        "\n",
        "    return ela_image\n",
        "\n",
        "def display_ela(image_path, ela_result):\n",
        "\n",
        "    original = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # Plot original and ELA result\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    axes[0].imshow(np.array(original))\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(np.array(ela_result))\n",
        "    axes[1].set_title('ELA Result')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage with your specific image path\n",
        "image_path = '/content/drive/MyDrive/Artificial Intelligence part_1/Test/Fake/fake_1008.jpg'\n",
        "ela_image = perform_ela(image_path)\n",
        "display_ela(image_path, ela_image)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ASSsj21XSEJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########### REAL\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def perform_ela(image_path, quality=95):\n",
        "\n",
        "\n",
        "\n",
        "    original = Image.open(image_path).convert('RGB')\n",
        "\n",
        "\n",
        "    temp_path = 'temp_compressed.jpg'\n",
        "    original.save(temp_path, 'JPEG', quality=quality)\n",
        "\n",
        "\n",
        "    compressed = Image.open(temp_path)\n",
        "\n",
        "    ela_image = ImageChops.difference(original, compressed)\n",
        "\n",
        "\n",
        "    extrema = ela_image.getextrema()\n",
        "    max_diff = max([ex[1] for ex in extrema])\n",
        "    scale = 255.0 / max_diff if max_diff != 0 else 1\n",
        "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
        "\n",
        "    return ela_image\n",
        "\n",
        "def display_ela(image_path, ela_result):\n",
        "\n",
        "    original = Image.open(image_path).convert('RGB')\n",
        "\n",
        "    # Plot original and ELA result\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    axes[0].imshow(np.array(original))\n",
        "    axes[0].set_title('Original Image')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(np.array(ela_result))\n",
        "    axes[1].set_title('ELA Result')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage with your specific image path\n",
        "image_path = '/content/drive/MyDrive/Artificial Intelligence part_1/Test/Real/real_10 - Copy.jpg'\n",
        "ela_image = perform_ela(image_path)\n",
        "display_ela(image_path, ela_image)"
      ],
      "metadata": {
        "id": "fi1uz9D3Vpy-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}